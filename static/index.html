<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Text to Speech</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        textarea {
            height: 100px;
            padding: 10px;
        }
        button {
            padding: 10px 20px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        button:hover {
            background-color: #0056b3;
        }
        #audioPlayer {
            width: 100%;
            margin-top: 20px;
        }
        .form-group {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        label {
            font-weight: bold;
        }
        .microphone-btn {
            font-size: 24px;
            background: none;
            border: none;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Text to Speech Converter</h1>
        <textarea id="textInput" placeholder="Enter text to convert..."></textarea>
        <button onclick="convertToSpeech()">Convert to Speech</button>
        <audio id="audioPlayer" controls></audio>
        
        <h2>Webhook Data</h2>
        <form method="POST" action="/api/webhook_form">
            <div class="form-group">
                <label for="patientInfo">Patient Information:</label>
                <textarea id="patientInfo" name="patient" placeholder="Enter patient information"></textarea>
    
                <label for="caseStudy">Case Study:</label>
                <textarea id="caseStudy" name="case_study" placeholder="Enter case study"></textarea>
    
                <label for="userMessage">User Message:</label>
                <textarea id="userMessage" name="user_message" placeholder="Enter user message"></textarea>
    
                <label for="patientMessage">Patient Message:</label>
                <textarea id="patientMessage" name="patient_message" placeholder="Enter patient message"></textarea>
    
                <label for="lastMessage">Last Message:</label>
                <textarea id="lastMessage" name="last_message" placeholder="Enter last message"></textarea>
    
                <button type="submit">Send to Webhook</button>
            </div>
        </form>
        <!-- New button to test webhook TTS -->
        <button onclick="playWebhookTTSAudio()">Play Webhook TTS (Hello)</button>
        <!-- New button to record audio via MediaRecorder -->
        <button id="whisperBtn">Record & Send (OpenAI Whisper)</button>
    </div>

    <script>
        async function convertToSpeech() {
            const text = document.getElementById('textInput').value;
            const audioPlayer = document.getElementById('audioPlayer');
            
            if (!text.trim()) {
                alert('Please enter text to convert');
                return;
            }
            
            try {
                const response = await fetch('/api/tts', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Accept': 'audio/mpeg',
                    },
                    body: JSON.stringify({
                        text: text
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Conversion error');
                }

                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                
                audioPlayer.src = audioUrl;
                await audioPlayer.play();
            } catch (error) {
                console.error('Error:', error);
                alert(`An error occurred: ${error.message}`);
            }
        }
        
        async function playWebhookTTSAudio() {
            // New function: sends POST to /api/webhook_tts and plays the returned audio
            const audioPlayer = document.getElementById('audioPlayer');
            try {
                const response = await fetch('/api/webhook_tts', {
                    method: 'POST'
                });
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Error in TTS webhook');
                }
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                audioPlayer.src = audioUrl;
                await audioPlayer.play();
            } catch (error) {
                console.error('Error:', error);
                alert(`An error occurred: ${error.message}`);
            }
        }

        function startSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                alert("Speech Recognition API not supported in this browser.");
                return;
            }
            const recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';
            
            recognition.onstart = () => {
                console.log("Speech recognition started");
            };
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                console.log("Recognized:", transcript);
                fetch('/api/stt', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ transcript: transcript })
                })
                .then(response => response.json())
                .then(data => console.log("Server response:", data))
                .catch(error => console.error("Error sending transcript:", error));
            };
            recognition.onerror = (event) => {
                console.error("Speech recognition error:", event.error);
            };
            recognition.onend = () => {
                console.log("Speech recognition ended");
            };
            recognition.start();
        }

        let mediaRecorder;
        let audioChunks = [];

        const whisperBtn = document.getElementById('whisperBtn');
        whisperBtn.addEventListener('click', async () => {
            if (!mediaRecorder || mediaRecorder.state === "inactive") {
                // Request mic access & start recording
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    audioChunks = [];
                    mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };
                    mediaRecorder.onstop = sendAudioToWhisper;
                    mediaRecorder.start();
                    whisperBtn.textContent = "Stop Recording";
                } catch (err) {
                    alert("Microphone access error: " + err);
                }
            } else {
                // Stop recording
                mediaRecorder.stop();
                whisperBtn.textContent = "Record & Send (OpenAI Whisper)";
            }
        });

        async function sendAudioToWhisper() {
            if (!audioChunks.length) {
                console.error("No audio data collected");
                return;
            }
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const formData = new FormData();
            formData.append('audio_file', audioBlob, 'recording.webm');

            try {
                const response = await fetch('/api/stt_whisper', {
                    method: 'POST',
                    body: formData
                });
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Whisper transcription failed');
                }
                const data = await response.json();
                console.log("Whisper transcript:", data.transcript);
            } catch (error) {
                console.error("Error uploading audio:", error);
                alert("Error: " + error.message);
            }
        }
    </script>
</body>
</html>
